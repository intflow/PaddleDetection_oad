I0509 16:11:36.962347 93749 tcp_utils.cc:107] Retry to connect to 127.0.1.1:60572 while the server is not yet listening.
I0509 16:11:39.962792 93749 tcp_utils.cc:130] Successfully connected to 127.0.1.1:60572
W0509 16:11:41.599470 93749 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.4
W0509 16:11:41.601994 93749 gpu_resources.cc:91] device: 1, cuDNN Version: 8.2.
[2023-05-09 16:11:42,175] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1], check/clip group: [1]
loading annotations into memory...
Done (t=0.13s)
creating index...
index created!
W0509 16:11:48.897564 93749 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Backward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool)
1   egr::RunBackward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&)
2   Conv2dGradNodeFinal::operator()(paddle::small_vector<std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conv2d_grad(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, paddle::experimental::Tensor*, paddle::experimental::Tensor*)
4   void phi::ConvCudnnGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DnnWorkspaceHandle::RunFunc(std::function<void (void*)> const&, unsigned long)
6   std::_Function_handler<void (void*), phi::ConvCudnnGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, phi::DenseTensor*, phi::DenseTensor*)::{lambda(void*)#1}>::_M_invoke(std::_Any_data const&, void*&&)

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1683616314 (unix time) try "date -d @1683616314" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x16dd4) received by PID 93749 (TID 0x7f74027b6740) from PID 93652 ***]

I0509 16:12:06.084966 94884 tcp_utils.cc:107] Retry to connect to 127.0.1.1:58255 while the server is not yet listening.
I0509 16:12:09.085206 94884 tcp_utils.cc:130] Successfully connected to 127.0.1.1:58255
W0509 16:12:10.723832 94884 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.4
W0509 16:12:10.726344 94884 gpu_resources.cc:91] device: 1, cuDNN Version: 8.2.
[2023-05-09 16:12:11,295] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1], check/clip group: [1]
loading annotations into memory...
Done (t=1.95s)
creating index...
index created!
W0509 16:12:23.527822 94884 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
I0510 10:49:07.568816 32355 tcp_utils.cc:130] Successfully connected to 127.0.1.1:35814
W0510 10:49:09.377434 32355 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0510 10:49:09.380080 32355 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
[2023-05-10 10:49:11,596] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 6, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1, 2, 3, 4, 5], check/clip group: [1]
loading annotations into memory...
Done (t=1.77s)
creating index...
index created!
W0510 10:50:01.954986 32355 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
W0510 15:53:15.026957 14377 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0510 15:53:15.030684 14377 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
  0%|          | 0/372 [00:00<?, ?it/s]  0%|          | 1/372 [00:01<09:15,  1.50s/it]  1%|          | 4/372 [00:01<01:57,  3.12it/s]  2%|▏         | 7/372 [00:01<01:01,  5.89it/s]  3%|▎         | 10/372 [00:01<00:41,  8.77it/s]  3%|▎         | 13/372 [00:01<00:30, 11.70it/s]  4%|▍         | 16/372 [00:02<00:25, 13.90it/s]  5%|▌         | 19/372 [00:02<00:22, 15.66it/s]  6%|▌         | 22/372 [00:02<00:19, 17.60it/s]  7%|▋         | 25/372 [00:02<00:18, 18.82it/s]  8%|▊         | 28/372 [00:02<00:17, 20.10it/s]  8%|▊         | 31/372 [00:02<00:16, 20.80it/s]  9%|▉         | 34/372 [00:02<00:15, 21.88it/s] 10%|▉         | 37/372 [00:03<00:14, 22.62it/s] 11%|█         | 40/372 [00:03<00:14, 22.89it/s] 12%|█▏        | 43/372 [00:03<00:14, 23.42it/s] 12%|█▏        | 46/372 [00:03<00:13, 23.35it/s] 13%|█▎        | 49/372 [00:03<00:13, 23.76it/s] 14%|█▍        | 52/372 [00:03<00:13, 23.93it/s] 15%|█▍        | 55/372 [00:03<00:13, 23.41it/s] 16%|█▌        | 58/372 [00:03<00:13, 24.11it/s] 16%|█▋        | 61/372 [00:04<00:12, 24.29it/s] 17%|█▋        | 64/372 [00:04<00:12, 24.37it/s] 18%|█▊        | 67/372 [00:04<00:12, 24.81it/s] 19%|█▉        | 70/372 [00:04<00:12, 24.74it/s] 20%|█▉        | 73/372 [00:04<00:11, 25.24it/s] 20%|██        | 76/372 [00:04<00:11, 25.60it/s] 21%|██        | 79/372 [00:04<00:11, 25.89it/s] 22%|██▏       | 82/372 [00:04<00:11, 25.26it/s] 23%|██▎       | 85/372 [00:04<00:11, 25.00it/s] 24%|██▎       | 88/372 [00:05<00:11, 25.14it/s] 24%|██▍       | 91/372 [00:05<00:11, 25.25it/s] 25%|██▌       | 94/372 [00:05<00:11, 25.24it/s] 26%|██▌       | 97/372 [00:05<00:10, 25.37it/s] 27%|██▋       | 100/372 [00:05<00:10, 25.41it/s] 28%|██▊       | 103/372 [00:05<00:10, 25.60it/s] 28%|██▊       | 106/372 [00:05<00:10, 25.36it/s] 29%|██▉       | 109/372 [00:05<00:10, 25.50it/s] 30%|███       | 112/372 [00:06<00:10, 23.99it/s] 31%|███       | 115/372 [00:06<00:11, 23.36it/s] 32%|███▏      | 118/372 [00:06<00:10, 23.41it/s] 33%|███▎      | 121/372 [00:06<00:10, 23.54it/s] 33%|███▎      | 124/372 [00:06<00:10, 24.13it/s] 34%|███▍      | 127/372 [00:06<00:10, 24.17it/s] 35%|███▍      | 130/372 [00:06<00:09, 24.44it/s] 36%|███▌      | 133/372 [00:06<00:09, 23.93it/s] 37%|███▋      | 136/372 [00:07<00:09, 24.78it/s] 37%|███▋      | 139/372 [00:07<00:09, 25.02it/s] 38%|███▊      | 142/372 [00:07<00:09, 23.20it/s] 39%|███▉      | 145/372 [00:07<00:09, 23.92it/s] 40%|███▉      | 148/372 [00:07<00:09, 24.58it/s] 41%|████      | 151/372 [00:07<00:08, 24.98it/s] 41%|████▏     | 154/372 [00:07<00:08, 25.31it/s] 42%|████▏     | 157/372 [00:07<00:08, 25.09it/s] 43%|████▎     | 160/372 [00:08<00:08, 25.14it/s] 44%|████▍     | 163/372 [00:08<00:08, 25.44it/s] 45%|████▍     | 166/372 [00:08<00:08, 25.59it/s] 45%|████▌     | 169/372 [00:08<00:07, 25.67it/s] 46%|████▌     | 172/372 [00:08<00:07, 25.23it/s] 47%|████▋     | 175/372 [00:08<00:08, 24.62it/s] 48%|████▊     | 178/372 [00:08<00:08, 23.82it/s] 49%|████▊     | 181/372 [00:08<00:08, 23.31it/s] 49%|████▉     | 184/372 [00:09<00:07, 23.54it/s] 50%|█████     | 187/372 [00:09<00:07, 23.90it/s] 51%|█████     | 190/372 [00:09<00:07, 24.53it/s] 52%|█████▏    | 193/372 [00:09<00:07, 24.98it/s] 53%|█████▎    | 196/372 [00:09<00:07, 25.09it/s] 53%|█████▎    | 199/372 [00:09<00:06, 25.39it/s] 54%|█████▍    | 202/372 [00:09<00:06, 25.68it/s] 55%|█████▌    | 205/372 [00:09<00:06, 25.89it/s] 56%|█████▌    | 208/372 [00:09<00:06, 25.99it/s] 57%|█████▋    | 211/372 [00:10<00:06, 26.02it/s] 58%|█████▊    | 214/372 [00:10<00:06, 25.38it/s] 58%|█████▊    | 217/372 [00:10<00:06, 25.32it/s] 59%|█████▉    | 220/372 [00:10<00:06, 25.13it/s] 60%|█████▉    | 223/372 [00:10<00:06, 24.11it/s] 61%|██████    | 226/372 [00:10<00:06, 23.81it/s] 62%|██████▏   | 229/372 [00:10<00:06, 23.20it/s] 62%|██████▏   | 232/372 [00:10<00:06, 22.83it/s] 63%|██████▎   | 235/372 [00:11<00:06, 22.83it/s] 64%|██████▍   | 238/372 [00:11<00:05, 23.57it/s] 65%|██████▍   | 241/372 [00:11<00:05, 24.32it/s] 66%|██████▌   | 244/372 [00:11<00:05, 24.64it/s] 66%|██████▋   | 247/372 [00:11<00:05, 24.82it/s] 67%|██████▋   | 250/372 [00:11<00:04, 24.78it/s] 68%|██████▊   | 253/372 [00:11<00:04, 25.11it/s] 69%|██████▉   | 256/372 [00:11<00:04, 25.28it/s] 70%|██████▉   | 259/372 [00:12<00:04, 25.42it/s] 70%|███████   | 262/372 [00:12<00:04, 25.83it/s] 71%|███████   | 265/372 [00:12<00:04, 25.38it/s] 72%|███████▏  | 268/372 [00:12<00:04, 25.34it/s] 73%|███████▎  | 271/372 [00:12<00:03, 25.40it/s] 74%|███████▎  | 274/372 [00:12<00:03, 25.07it/s] 74%|███████▍  | 277/372 [00:12<00:03, 24.50it/s] 75%|███████▌  | 280/372 [00:12<00:03, 24.88it/s] 76%|███████▌  | 283/372 [00:13<00:03, 24.89it/s] 77%|███████▋  | 286/372 [00:13<00:03, 24.15it/s] 78%|███████▊  | 289/372 [00:13<00:03, 24.49it/s] 78%|███████▊  | 292/372 [00:13<00:03, 24.59it/s] 79%|███████▉  | 295/372 [00:13<00:03, 24.78it/s] 80%|████████  | 298/372 [00:13<00:02, 24.81it/s] 81%|████████  | 301/372 [00:13<00:02, 25.00it/s] 82%|████████▏ | 304/372 [00:13<00:02, 25.19it/s] 83%|████████▎ | 307/372 [00:13<00:02, 25.12it/s] 83%|████████▎ | 310/372 [00:14<00:02, 25.39it/s] 84%|████████▍ | 313/372 [00:14<00:02, 25.49it/s] 85%|████████▍ | 316/372 [00:14<00:02, 26.02it/s] 86%|████████▌ | 319/372 [00:14<00:02, 24.16it/s] 87%|████████▋ | 322/372 [00:14<00:02, 24.27it/s] 87%|████████▋ | 325/372 [00:14<00:01, 24.69it/s] 88%|████████▊ | 328/372 [00:14<00:01, 25.14it/s] 89%|████████▉ | 331/372 [00:14<00:01, 25.51it/s] 90%|████████▉ | 334/372 [00:15<00:01, 25.72it/s] 91%|█████████ | 337/372 [00:15<00:01, 25.94it/s] 91%|█████████▏| 340/372 [00:15<00:01, 25.82it/s] 92%|█████████▏| 343/372 [00:15<00:01, 24.94it/s] 93%|█████████▎| 346/372 [00:15<00:01, 24.87it/s] 94%|█████████▍| 349/372 [00:15<00:00, 25.50it/s] 95%|█████████▍| 352/372 [00:15<00:00, 25.61it/s] 95%|█████████▌| 355/372 [00:15<00:00, 25.70it/s] 96%|█████████▌| 358/372 [00:15<00:00, 25.06it/s] 97%|█████████▋| 361/372 [00:16<00:00, 25.26it/s] 98%|█████████▊| 364/372 [00:16<00:00, 25.83it/s] 99%|█████████▊| 367/372 [00:16<00:00, 26.29it/s] 99%|█████████▉| 370/372 [00:16<00:00, 26.97it/s]100%|██████████| 372/372 [00:16<00:00, 22.54it/s]
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
W0510 15:55:09.495348 14838 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0510 15:55:09.498268 14838 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
  0%|          | 0/372 [00:00<?, ?it/s]  0%|          | 1/372 [00:01<08:53,  1.44s/it]  1%|          | 4/372 [00:01<01:52,  3.28it/s]  2%|▏         | 7/372 [00:01<00:59,  6.18it/s]  3%|▎         | 10/372 [00:01<00:39,  9.23it/s]  3%|▎         | 13/372 [00:01<00:29, 12.24it/s]  4%|▍         | 16/372 [00:02<00:23, 15.06it/s]  5%|▌         | 19/372 [00:02<00:20, 17.56it/s]  6%|▌         | 22/372 [00:02<00:17, 19.50it/s]  7%|▋         | 25/372 [00:02<00:16, 21.16it/s]  8%|▊         | 28/372 [00:02<00:15, 22.46it/s]  8%|▊         | 31/372 [00:02<00:14, 23.42it/s]  9%|▉         | 34/372 [00:02<00:14, 23.88it/s] 10%|▉         | 37/372 [00:02<00:13, 24.28it/s] 11%|█         | 40/372 [00:02<00:13, 24.82it/s] 12%|█▏        | 43/372 [00:03<00:13, 25.20it/s] 12%|█▏        | 46/372 [00:03<00:12, 25.46it/s] 13%|█▎        | 49/372 [00:03<00:12, 25.67it/s] 14%|█▍        | 52/372 [00:03<00:12, 25.82it/s] 15%|█▍        | 55/372 [00:03<00:12, 25.92it/s] 16%|█▌        | 58/372 [00:03<00:12, 25.60it/s] 16%|█▋        | 61/372 [00:03<00:12, 25.80it/s] 17%|█▋        | 64/372 [00:03<00:12, 25.61it/s] 18%|█▊        | 67/372 [00:03<00:11, 25.70it/s] 19%|█▉        | 70/372 [00:04<00:11, 25.85it/s] 20%|█▉        | 73/372 [00:04<00:11, 25.92it/s] 20%|██        | 76/372 [00:04<00:11, 26.04it/s] 21%|██        | 79/372 [00:04<00:11, 26.08it/s] 22%|██▏       | 82/372 [00:04<00:11, 26.14it/s] 23%|██▎       | 85/372 [00:04<00:10, 26.22it/s] 24%|██▎       | 88/372 [00:04<00:10, 26.28it/s] 24%|██▍       | 91/372 [00:04<00:10, 26.24it/s] 25%|██▌       | 94/372 [00:05<00:10, 26.07it/s] 26%|██▌       | 97/372 [00:05<00:10, 26.06it/s] 27%|██▋       | 100/372 [00:05<00:10, 26.10it/s] 28%|██▊       | 103/372 [00:05<00:10, 25.94it/s] 28%|██▊       | 106/372 [00:05<00:10, 25.84it/s] 29%|██▉       | 109/372 [00:05<00:10, 25.72it/s] 30%|███       | 112/372 [00:05<00:10, 25.93it/s] 31%|███       | 115/372 [00:05<00:09, 26.05it/s] 32%|███▏      | 118/372 [00:05<00:09, 26.12it/s] 33%|███▎      | 121/372 [00:06<00:09, 25.90it/s] 33%|███▎      | 124/372 [00:06<00:09, 26.04it/s] 34%|███▍      | 127/372 [00:06<00:09, 26.09it/s] 35%|███▍      | 130/372 [00:06<00:09, 26.14it/s] 36%|███▌      | 133/372 [00:06<00:09, 26.20it/s] 37%|███▋      | 136/372 [00:06<00:09, 26.22it/s] 37%|███▋      | 139/372 [00:06<00:08, 26.22it/s] 38%|███▊      | 142/372 [00:06<00:08, 26.18it/s] 39%|███▉      | 145/372 [00:06<00:08, 26.16it/s] 40%|███▉      | 148/372 [00:07<00:08, 25.59it/s] 41%|████      | 151/372 [00:07<00:08, 25.45it/s] 41%|████▏     | 154/372 [00:07<00:08, 25.63it/s] 42%|████▏     | 157/372 [00:07<00:08, 25.74it/s] 43%|████▎     | 160/372 [00:07<00:08, 25.57it/s] 44%|████▍     | 163/372 [00:07<00:08, 25.75it/s] 45%|████▍     | 166/372 [00:07<00:07, 25.84it/s] 45%|████▌     | 169/372 [00:07<00:07, 25.93it/s] 46%|████▌     | 172/372 [00:08<00:07, 25.93it/s] 47%|████▋     | 175/372 [00:08<00:07, 25.93it/s] 48%|████▊     | 178/372 [00:08<00:07, 25.74it/s] 49%|████▊     | 181/372 [00:08<00:07, 25.84it/s] 49%|████▉     | 184/372 [00:08<00:07, 25.93it/s] 50%|█████     | 187/372 [00:08<00:07, 25.99it/s] 51%|█████     | 190/372 [00:08<00:06, 26.06it/s] 52%|█████▏    | 193/372 [00:08<00:06, 26.06it/s] 53%|█████▎    | 196/372 [00:08<00:06, 26.14it/s] 53%|█████▎    | 199/372 [00:09<00:06, 26.12it/s] 54%|█████▍    | 202/372 [00:09<00:06, 26.18it/s] 55%|█████▌    | 205/372 [00:09<00:06, 25.70it/s] 56%|█████▌    | 208/372 [00:09<00:06, 25.84it/s] 57%|█████▋    | 211/372 [00:09<00:06, 25.87it/s] 58%|█████▊    | 214/372 [00:09<00:06, 25.44it/s] 58%|█████▊    | 217/372 [00:09<00:06, 25.59it/s] 59%|█████▉    | 220/372 [00:09<00:05, 25.72it/s] 60%|█████▉    | 223/372 [00:10<00:05, 25.81it/s] 61%|██████    | 226/372 [00:10<00:05, 25.89it/s] 62%|██████▏   | 229/372 [00:10<00:05, 25.93it/s] 62%|██████▏   | 232/372 [00:10<00:05, 25.76it/s] 63%|██████▎   | 235/372 [00:10<00:05, 25.88it/s] 64%|██████▍   | 238/372 [00:10<00:05, 25.99it/s] 65%|██████▍   | 241/372 [00:10<00:05, 26.03it/s] 66%|██████▌   | 244/372 [00:10<00:04, 26.11it/s] 66%|██████▋   | 247/372 [00:10<00:04, 26.13it/s] 67%|██████▋   | 250/372 [00:11<00:04, 26.11it/s] 68%|██████▊   | 253/372 [00:11<00:04, 26.11it/s] 69%|██████▉   | 256/372 [00:11<00:04, 26.13it/s] 70%|██████▉   | 259/372 [00:11<00:04, 26.16it/s] 70%|███████   | 262/372 [00:11<00:04, 26.17it/s] 71%|███████   | 265/372 [00:11<00:04, 26.20it/s] 72%|███████▏  | 268/372 [00:11<00:03, 26.21it/s] 73%|███████▎  | 271/372 [00:11<00:03, 26.18it/s] 74%|███████▎  | 274/372 [00:11<00:03, 26.14it/s] 74%|███████▍  | 277/372 [00:12<00:03, 25.88it/s] 75%|███████▌  | 280/372 [00:12<00:03, 26.03it/s] 76%|███████▌  | 283/372 [00:12<00:03, 26.09it/s] 77%|███████▋  | 286/372 [00:12<00:03, 26.12it/s] 78%|███████▊  | 289/372 [00:12<00:03, 26.06it/s] 78%|███████▊  | 292/372 [00:12<00:03, 26.10it/s] 79%|███████▉  | 295/372 [00:12<00:02, 26.15it/s] 80%|████████  | 298/372 [00:12<00:02, 26.17it/s] 81%|████████  | 301/372 [00:13<00:02, 26.02it/s] 82%|████████▏ | 304/372 [00:13<00:02, 26.06it/s] 83%|████████▎ | 307/372 [00:13<00:02, 26.14it/s] 83%|████████▎ | 310/372 [00:13<00:02, 26.13it/s] 84%|████████▍ | 313/372 [00:13<00:02, 26.17it/s] 85%|████████▍ | 316/372 [00:13<00:02, 26.23it/s] 86%|████████▌ | 319/372 [00:13<00:02, 26.31it/s] 87%|████████▋ | 322/372 [00:13<00:01, 26.30it/s] 87%|████████▋ | 325/372 [00:13<00:01, 26.20it/s] 88%|████████▊ | 328/372 [00:14<00:01, 26.22it/s] 89%|████████▉ | 331/372 [00:14<00:01, 26.15it/s] 90%|████████▉ | 334/372 [00:14<00:01, 26.15it/s] 91%|█████████ | 337/372 [00:14<00:01, 26.17it/s] 91%|█████████▏| 340/372 [00:14<00:01, 26.22it/s] 92%|█████████▏| 343/372 [00:14<00:01, 26.24it/s] 93%|█████████▎| 346/372 [00:14<00:00, 26.24it/s] 94%|█████████▍| 349/372 [00:14<00:00, 26.24it/s] 95%|█████████▍| 352/372 [00:14<00:00, 26.21it/s] 95%|█████████▌| 355/372 [00:15<00:00, 26.14it/s] 96%|█████████▌| 358/372 [00:15<00:00, 26.06it/s] 97%|█████████▋| 361/372 [00:15<00:00, 26.09it/s] 98%|█████████▊| 364/372 [00:15<00:00, 26.10it/s] 99%|█████████▊| 367/372 [00:15<00:00, 26.15it/s] 99%|█████████▉| 370/372 [00:15<00:00, 26.41it/s]100%|██████████| 372/372 [00:15<00:00, 23.69it/s]
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
I0510 16:51:49.937408 15377 tcp_utils.cc:107] Retry to connect to 127.0.1.1:50995 while the server is not yet listening.
I0510 16:51:52.937803 15377 tcp_utils.cc:130] Successfully connected to 127.0.1.1:50995
W0510 16:51:55.132303 15377 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0510 16:51:55.135131 15377 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
[2023-05-10 16:51:57,444] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 6, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1, 2, 3, 4, 5], check/clip group: [1]
loading annotations into memory...
Done (t=1.70s)
creating index...
index created!
W0510 16:52:56.354935 15377 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
W0511 09:17:52.494217 30945 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0511 09:17:52.497475 30945 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
  0%|          | 0/372 [00:00<?, ?it/s]  0%|          | 1/372 [00:01<08:35,  1.39s/it]  1%|          | 4/372 [00:01<01:48,  3.38it/s]  2%|▏         | 7/372 [00:01<00:58,  6.28it/s]  3%|▎         | 10/372 [00:01<00:38,  9.37it/s]  3%|▎         | 13/372 [00:01<00:28, 12.39it/s]  4%|▍         | 16/372 [00:01<00:23, 15.17it/s]  5%|▌         | 19/372 [00:02<00:20, 17.45it/s]  6%|▌         | 22/372 [00:02<00:17, 19.49it/s]  7%|▋         | 25/372 [00:02<00:16, 21.12it/s]  8%|▊         | 28/372 [00:02<00:15, 22.40it/s]  8%|▊         | 31/372 [00:02<00:14, 23.40it/s]  9%|▉         | 34/372 [00:02<00:14, 23.94it/s] 10%|▉         | 37/372 [00:02<00:13, 24.32it/s] 11%|█         | 40/372 [00:02<00:13, 24.71it/s] 12%|█▏        | 43/372 [00:03<00:13, 24.96it/s] 12%|█▏        | 46/372 [00:03<00:12, 25.19it/s] 13%|█▎        | 49/372 [00:03<00:12, 25.26it/s] 14%|█▍        | 52/372 [00:03<00:12, 25.39it/s] 15%|█▍        | 55/372 [00:03<00:12, 25.49it/s] 16%|█▌        | 58/372 [00:03<00:12, 25.23it/s] 16%|█▋        | 61/372 [00:03<00:12, 25.17it/s] 17%|█▋        | 64/372 [00:03<00:12, 25.28it/s] 18%|█▊        | 67/372 [00:03<00:12, 25.38it/s] 19%|█▉        | 70/372 [00:04<00:11, 25.55it/s] 20%|█▉        | 73/372 [00:04<00:11, 25.67it/s] 20%|██        | 76/372 [00:04<00:11, 25.75it/s] 21%|██        | 79/372 [00:04<00:11, 25.81it/s] 22%|██▏       | 82/372 [00:04<00:11, 25.85it/s] 23%|██▎       | 85/372 [00:04<00:11, 25.85it/s] 24%|██▎       | 88/372 [00:04<00:10, 25.87it/s] 24%|██▍       | 91/372 [00:04<00:10, 25.92it/s] 25%|██▌       | 94/372 [00:05<00:10, 25.92it/s] 26%|██▌       | 97/372 [00:05<00:10, 25.87it/s] 27%|██▋       | 100/372 [00:05<00:10, 25.69it/s] 28%|██▊       | 103/372 [00:05<00:10, 25.60it/s] 28%|██▊       | 106/372 [00:05<00:10, 25.71it/s] 29%|██▉       | 109/372 [00:05<00:10, 25.41it/s] 30%|███       | 112/372 [00:05<00:10, 25.24it/s] 31%|███       | 115/372 [00:05<00:10, 25.41it/s] 32%|███▏      | 118/372 [00:05<00:09, 25.52it/s] 33%|███▎      | 121/372 [00:06<00:09, 25.60it/s] 33%|███▎      | 124/372 [00:06<00:09, 25.49it/s] 34%|███▍      | 127/372 [00:06<00:09, 25.56it/s] 35%|███▍      | 130/372 [00:06<00:09, 25.42it/s] 36%|███▌      | 133/372 [00:06<00:09, 25.57it/s] 37%|███▋      | 136/372 [00:06<00:09, 25.65it/s] 37%|███▋      | 139/372 [00:06<00:09, 25.74it/s] 38%|███▊      | 142/372 [00:06<00:08, 25.77it/s] 39%|███▉      | 145/372 [00:07<00:08, 25.29it/s] 40%|███▉      | 148/372 [00:07<00:09, 24.82it/s] 41%|████      | 151/372 [00:07<00:08, 24.96it/s] 41%|████▏     | 154/372 [00:07<00:08, 25.08it/s] 42%|████▏     | 157/372 [00:07<00:08, 25.22it/s] 43%|████▎     | 160/372 [00:07<00:08, 25.36it/s] 44%|████▍     | 163/372 [00:07<00:08, 25.46it/s] 45%|████▍     | 166/372 [00:07<00:08, 25.26it/s] 45%|████▌     | 169/372 [00:07<00:07, 25.41it/s] 46%|████▌     | 172/372 [00:08<00:07, 25.52it/s] 47%|████▋     | 175/372 [00:08<00:07, 25.65it/s] 48%|████▊     | 178/372 [00:08<00:07, 25.67it/s] 49%|████▊     | 181/372 [00:08<00:07, 25.74it/s] 49%|████▉     | 184/372 [00:08<00:07, 25.79it/s] 50%|█████     | 187/372 [00:08<00:07, 25.86it/s] 51%|█████     | 190/372 [00:08<00:07, 25.77it/s] 52%|█████▏    | 193/372 [00:08<00:06, 25.80it/s] 53%|█████▎    | 196/372 [00:09<00:06, 25.80it/s] 53%|█████▎    | 199/372 [00:09<00:06, 25.87it/s] 54%|█████▍    | 202/372 [00:09<00:06, 25.86it/s] 55%|█████▌    | 205/372 [00:09<00:06, 25.83it/s] 56%|█████▌    | 208/372 [00:09<00:06, 25.77it/s] 57%|█████▋    | 211/372 [00:09<00:06, 25.77it/s] 58%|█████▊    | 214/372 [00:09<00:06, 25.67it/s] 58%|█████▊    | 217/372 [00:09<00:06, 25.63it/s] 59%|█████▉    | 220/372 [00:09<00:05, 25.60it/s] 60%|█████▉    | 223/372 [00:10<00:05, 25.30it/s] 61%|██████    | 226/372 [00:10<00:05, 25.40it/s] 62%|██████▏   | 229/372 [00:10<00:05, 24.81it/s] 62%|██████▏   | 232/372 [00:10<00:05, 25.02it/s] 63%|██████▎   | 235/372 [00:10<00:05, 25.15it/s] 64%|██████▍   | 238/372 [00:10<00:05, 25.21it/s] 65%|██████▍   | 241/372 [00:10<00:05, 25.34it/s] 66%|██████▌   | 244/372 [00:10<00:05, 25.40it/s] 66%|██████▋   | 247/372 [00:11<00:04, 25.41it/s] 67%|██████▋   | 250/372 [00:11<00:04, 25.44it/s] 68%|██████▊   | 253/372 [00:11<00:04, 25.15it/s] 69%|██████▉   | 256/372 [00:11<00:04, 25.26it/s] 70%|██████▉   | 259/372 [00:11<00:04, 25.31it/s] 70%|███████   | 262/372 [00:11<00:04, 25.37it/s] 71%|███████   | 265/372 [00:11<00:04, 25.25it/s] 72%|███████▏  | 268/372 [00:11<00:04, 24.77it/s] 73%|███████▎  | 271/372 [00:11<00:03, 25.28it/s] 74%|███████▎  | 274/372 [00:12<00:03, 25.48it/s] 74%|███████▍  | 277/372 [00:12<00:03, 25.29it/s] 75%|███████▌  | 280/372 [00:12<00:03, 25.29it/s] 76%|███████▌  | 283/372 [00:12<00:03, 25.35it/s] 77%|███████▋  | 286/372 [00:12<00:03, 25.46it/s] 78%|███████▊  | 289/372 [00:12<00:03, 25.49it/s] 78%|███████▊  | 292/372 [00:12<00:03, 25.51it/s] 79%|███████▉  | 295/372 [00:12<00:03, 25.30it/s] 80%|████████  | 298/372 [00:13<00:02, 25.09it/s] 81%|████████  | 301/372 [00:13<00:02, 25.26it/s] 82%|████████▏ | 304/372 [00:13<00:02, 25.36it/s] 83%|████████▎ | 307/372 [00:13<00:02, 25.49it/s] 83%|████████▎ | 310/372 [00:13<00:02, 25.55it/s] 84%|████████▍ | 313/372 [00:13<00:02, 25.66it/s] 85%|████████▍ | 316/372 [00:13<00:02, 25.83it/s] 86%|████████▌ | 319/372 [00:13<00:02, 25.87it/s] 87%|████████▋ | 322/372 [00:13<00:01, 25.92it/s] 87%|████████▋ | 325/372 [00:14<00:01, 26.01it/s] 88%|████████▊ | 328/372 [00:14<00:01, 26.06it/s] 89%|████████▉ | 331/372 [00:14<00:01, 26.14it/s] 90%|████████▉ | 334/372 [00:14<00:01, 26.17it/s] 91%|█████████ | 337/372 [00:14<00:01, 26.21it/s] 91%|█████████▏| 340/372 [00:14<00:01, 26.27it/s] 92%|█████████▏| 343/372 [00:14<00:01, 26.29it/s] 93%|█████████▎| 346/372 [00:14<00:00, 26.37it/s] 94%|█████████▍| 349/372 [00:15<00:00, 26.49it/s] 95%|█████████▍| 352/372 [00:15<00:00, 26.53it/s] 95%|█████████▌| 355/372 [00:15<00:00, 26.02it/s] 96%|█████████▌| 358/372 [00:15<00:00, 26.09it/s] 97%|█████████▋| 361/372 [00:15<00:00, 26.15it/s] 98%|█████████▊| 364/372 [00:15<00:00, 26.21it/s] 99%|█████████▊| 367/372 [00:15<00:00, 26.27it/s] 99%|█████████▉| 370/372 [00:15<00:00, 26.66it/s]100%|██████████| 372/372 [00:15<00:00, 23.44it/s]
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
I0511 09:23:03.630337 31360 tcp_utils.cc:107] Retry to connect to 127.0.1.1:51953 while the server is not yet listening.
I0511 09:23:06.630594 31360 tcp_utils.cc:130] Successfully connected to 127.0.1.1:51953
W0511 09:23:08.504921 31360 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0511 09:23:08.507885 31360 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
[2023-05-11 09:23:11,376] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 6, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1, 2, 3, 4, 5], check/clip group: [1]
loading annotations into memory...
Done (t=1.72s)
creating index...
index created!
W0511 09:24:01.652031 31360 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
W0511 17:58:48.172410  4613 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0511 17:58:48.175808  4613 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
  0%|          | 0/372 [00:00<?, ?it/s]

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   add_ad_func(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&)
1   paddle::experimental::add(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&)
2   void phi::AddRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
3   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
4   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, paddle::experimental::DataType, unsigned long, bool) const
5   phi::DenseTensor::AllocateFrom(phi::Allocator*, paddle::experimental::DataType, unsigned long)
6   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1683795544 (unix time) try "date -d @1683795544" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x11b5) received by PID 4613 (TID 0x7fa99c3d9740) from PID 4533 ***]



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   squeeze_ad_func(paddle::experimental::Tensor const&, paddle::experimental::IntArrayBase<paddle::experimental::Tensor>)
1   paddle::experimental::squeeze_intermediate(paddle::experimental::Tensor const&, paddle::experimental::IntArrayBase<paddle::experimental::Tensor> const&)
2   paddle::experimental::PrepareData(paddle::experimental::Tensor const&, phi::TensorArgDef const&, paddle::experimental::TransformFlag const&)
3   paddle::experimental::TransformData(phi::DenseTensor*, phi::TensorArgDef const&, paddle::experimental::TransformFlag const&)
4   paddle::experimental::TransDataPlace(phi::DenseTensor const&, phi::Place)
5   paddle::framework::TensorCopySync(phi::DenseTensor const&, phi::Place const&, phi::DenseTensor*)
6   void paddle::memory::Copy<phi::Place, phi::Place>(phi::Place, void*, phi::Place, void const*, unsigned long, void*)
7   void paddle::memory::Copy<phi::GPUPlace, phi::GPUPinnedPlace>(phi::GPUPlace, void*, phi::GPUPinnedPlace, void const*, unsigned long, void*)
8   phi::backends::gpu::GpuMemcpySync(void*, void const*, unsigned long, cudaMemcpyKind)

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1683795560 (unix time) try "date -d @1683795560" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x7a22) received by PID 31360 (TID 0x7f8142321740) from PID 31266 ***]

/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
W0511 17:59:37.394682  4852 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0511 17:59:37.397819  4852 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
  0%|          | 0/372 [00:00<?, ?it/s]  0%|          | 1/372 [00:01<08:44,  1.41s/it]  1%|          | 4/372 [00:01<01:52,  3.28it/s]  2%|▏         | 7/372 [00:01<00:59,  6.15it/s]  3%|▎         | 10/372 [00:01<00:39,  9.16it/s]  3%|▎         | 13/372 [00:01<00:29, 12.14it/s]  4%|▍         | 16/372 [00:02<00:23, 14.90it/s]  5%|▌         | 19/372 [00:02<00:20, 17.32it/s]  6%|▌         | 22/372 [00:02<00:18, 18.85it/s]  7%|▋         | 25/372 [00:02<00:17, 19.83it/s]  8%|▊         | 28/372 [00:02<00:16, 20.84it/s]  8%|▊         | 31/372 [00:02<00:15, 21.57it/s]  9%|▉         | 34/372 [00:02<00:15, 22.19it/s] 10%|▉         | 37/372 [00:02<00:14, 23.10it/s] 11%|█         | 40/372 [00:03<00:14, 22.21it/s] 12%|█▏        | 43/372 [00:03<00:14, 22.59it/s] 12%|█▏        | 46/372 [00:03<00:14, 22.77it/s] 13%|█▎        | 49/372 [00:03<00:14, 22.88it/s] 14%|█▍        | 52/372 [00:03<00:13, 23.13it/s] 15%|█▍        | 55/372 [00:03<00:13, 22.82it/s] 16%|█▌        | 58/372 [00:03<00:14, 22.29it/s] 16%|█▋        | 61/372 [00:03<00:13, 22.61it/s] 17%|█▋        | 64/372 [00:04<00:13, 22.80it/s] 18%|█▊        | 67/372 [00:04<00:13, 22.90it/s] 19%|█▉        | 70/372 [00:04<00:13, 22.51it/s] 20%|█▉        | 73/372 [00:04<00:12, 23.27it/s] 20%|██        | 76/372 [00:04<00:12, 23.01it/s] 21%|██        | 79/372 [00:04<00:12, 22.65it/s] 22%|██▏       | 82/372 [00:04<00:12, 23.42it/s] 23%|██▎       | 85/372 [00:05<00:12, 23.62it/s] 24%|██▎       | 88/372 [00:05<00:11, 24.16it/s] 24%|██▍       | 91/372 [00:05<00:11, 24.61it/s] 25%|██▌       | 94/372 [00:05<00:11, 24.26it/s] 26%|██▌       | 97/372 [00:05<00:11, 24.77it/s] 27%|██▋       | 100/372 [00:05<00:11, 24.44it/s] 28%|██▊       | 103/372 [00:05<00:10, 24.59it/s] 28%|██▊       | 106/372 [00:05<00:10, 24.83it/s] 29%|██▉       | 109/372 [00:05<00:10, 24.72it/s] 30%|███       | 112/372 [00:06<00:10, 24.48it/s] 31%|███       | 115/372 [00:06<00:10, 24.77it/s] 32%|███▏      | 118/372 [00:06<00:10, 24.66it/s] 33%|███▎      | 121/372 [00:06<00:10, 24.49it/s] 33%|███▎      | 124/372 [00:06<00:10, 24.32it/s] 34%|███▍      | 127/372 [00:06<00:09, 24.68it/s] 35%|███▍      | 130/372 [00:06<00:09, 24.68it/s] 36%|███▌      | 133/372 [00:06<00:09, 24.95it/s] 37%|███▋      | 136/372 [00:07<00:09, 24.75it/s] 37%|███▋      | 139/372 [00:07<00:09, 24.74it/s] 38%|███▊      | 142/372 [00:07<00:09, 24.67it/s] 39%|███▉      | 145/372 [00:07<00:09, 24.77it/s] 40%|███▉      | 148/372 [00:07<00:08, 24.99it/s] 41%|████      | 151/372 [00:07<00:08, 24.81it/s] 41%|████▏     | 154/372 [00:07<00:08, 25.06it/s] 42%|████▏     | 157/372 [00:07<00:08, 24.91it/s] 43%|████▎     | 160/372 [00:08<00:08, 25.19it/s] 44%|████▍     | 163/372 [00:08<00:08, 25.10it/s] 45%|████▍     | 166/372 [00:08<00:08, 24.37it/s] 45%|████▌     | 169/372 [00:08<00:08, 24.76it/s] 46%|████▌     | 172/372 [00:08<00:08, 24.59it/s] 47%|████▋     | 175/372 [00:08<00:07, 24.98it/s] 48%|████▊     | 178/372 [00:08<00:07, 24.98it/s] 49%|████▊     | 181/372 [00:08<00:07, 25.19it/s] 49%|████▉     | 184/372 [00:08<00:07, 25.42it/s] 50%|█████     | 187/372 [00:09<00:07, 25.56it/s] 51%|█████     | 190/372 [00:09<00:07, 25.72it/s] 52%|█████▏    | 193/372 [00:09<00:06, 25.73it/s] 53%|█████▎    | 196/372 [00:09<00:06, 25.76it/s] 53%|█████▎    | 199/372 [00:09<00:06, 25.73it/s] 54%|█████▍    | 202/372 [00:09<00:06, 25.81it/s] 55%|█████▌    | 205/372 [00:09<00:06, 25.81it/s] 56%|█████▌    | 208/372 [00:09<00:06, 25.73it/s] 57%|█████▋    | 211/372 [00:10<00:06, 25.90it/s] 58%|█████▊    | 214/372 [00:10<00:06, 25.92it/s] 58%|█████▊    | 217/372 [00:10<00:05, 25.92it/s] 59%|█████▉    | 220/372 [00:10<00:05, 25.94it/s] 60%|█████▉    | 223/372 [00:10<00:05, 25.97it/s] 61%|██████    | 226/372 [00:10<00:05, 26.00it/s] 62%|██████▏   | 229/372 [00:10<00:05, 26.04it/s] 62%|██████▏   | 232/372 [00:10<00:05, 26.08it/s] 63%|██████▎   | 235/372 [00:10<00:05, 26.01it/s] 64%|██████▍   | 238/372 [00:11<00:05, 25.98it/s] 65%|██████▍   | 241/372 [00:11<00:05, 26.01it/s] 66%|██████▌   | 244/372 [00:11<00:04, 26.02it/s] 66%|██████▋   | 247/372 [00:11<00:04, 25.72it/s] 67%|██████▋   | 250/372 [00:11<00:04, 25.63it/s] 68%|██████▊   | 253/372 [00:11<00:04, 25.68it/s] 69%|██████▉   | 256/372 [00:11<00:04, 25.43it/s] 70%|██████▉   | 259/372 [00:11<00:04, 25.67it/s] 70%|███████   | 262/372 [00:12<00:04, 25.42it/s] 71%|███████   | 265/372 [00:12<00:04, 24.04it/s] 72%|███████▏  | 268/372 [00:12<00:04, 23.69it/s] 73%|███████▎  | 271/372 [00:12<00:04, 24.11it/s] 74%|███████▎  | 274/372 [00:12<00:03, 24.62it/s] 74%|███████▍  | 277/372 [00:12<00:03, 25.04it/s] 75%|███████▌  | 280/372 [00:12<00:03, 24.74it/s] 76%|███████▌  | 283/372 [00:12<00:03, 24.96it/s] 77%|███████▋  | 286/372 [00:13<00:03, 23.62it/s] 78%|███████▊  | 289/372 [00:13<00:03, 23.02it/s] 78%|███████▊  | 292/372 [00:13<00:03, 22.62it/s] 79%|███████▉  | 295/372 [00:13<00:03, 23.42it/s] 80%|████████  | 298/372 [00:13<00:03, 24.10it/s] 81%|████████  | 301/372 [00:13<00:02, 24.43it/s] 82%|████████▏ | 304/372 [00:13<00:02, 24.34it/s] 83%|████████▎ | 307/372 [00:13<00:02, 24.40it/s] 83%|████████▎ | 310/372 [00:13<00:02, 24.91it/s] 84%|████████▍ | 313/372 [00:14<00:02, 24.35it/s] 85%|████████▍ | 316/372 [00:14<00:02, 24.51it/s] 86%|████████▌ | 319/372 [00:14<00:02, 24.76it/s] 87%|████████▋ | 322/372 [00:14<00:01, 25.33it/s] 87%|████████▋ | 325/372 [00:14<00:01, 25.69it/s] 88%|████████▊ | 328/372 [00:14<00:01, 26.03it/s] 89%|████████▉ | 331/372 [00:14<00:01, 26.25it/s] 90%|████████▉ | 334/372 [00:14<00:01, 26.09it/s] 91%|█████████ | 337/372 [00:15<00:01, 26.19it/s] 91%|█████████▏| 340/372 [00:15<00:01, 26.31it/s] 92%|█████████▏| 343/372 [00:15<00:01, 26.35it/s] 93%|█████████▎| 346/372 [00:15<00:00, 26.40it/s] 94%|█████████▍| 349/372 [00:15<00:00, 26.42it/s] 95%|█████████▍| 352/372 [00:15<00:00, 26.53it/s] 95%|█████████▌| 355/372 [00:15<00:00, 26.58it/s] 96%|█████████▌| 358/372 [00:15<00:00, 26.65it/s] 97%|█████████▋| 361/372 [00:15<00:00, 26.69it/s] 98%|█████████▊| 364/372 [00:16<00:00, 26.61it/s] 99%|█████████▊| 367/372 [00:16<00:00, 26.70it/s] 99%|█████████▉| 370/372 [00:16<00:00, 27.06it/s]100%|██████████| 372/372 [00:16<00:00, 22.75it/s]
/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
I0512 00:16:17.714987 24979 tcp_utils.cc:130] Successfully connected to 127.0.1.1:38035
W0512 00:16:19.202116 24979 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0512 00:16:19.205080 24979 gpu_resources.cc:91] device: 1, cuDNN Version: 8.4.
[2023-05-12 00:16:21,524] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 6, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1, 2, 3, 4, 5], check/clip group: [1]
loading annotations into memory...
Done (t=1.93s)
creating index...
index created!
W0512 00:17:12.072340 24979 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
