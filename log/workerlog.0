/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py:169: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(module.__version__) < minver:
/root/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:108: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  long_ = _make_signed(np.long)
/opt/conda/lib/python3.8/site-packages/numba/core/types/__init__.py:109: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  ulong = _make_unsigned(np.long)
[2023-05-03 04:49:35,586] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 1, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0], check/clip group: [0]
loading annotations into memory...
Done (t=1.92s)
creating index...
index created!
[05/03 04:49:43] ppdet.data.source.coco INFO: Load [10498 samples valid, 3547 samples invalid] in file /DL_data_super_ssd/EFID2023/hallway/train/json/annotation.json.
W0503 04:49:44.038959 28962 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.7, Runtime API Version: 11.7
W0503 04:49:44.043627 28962 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
[05/03 04:49:46] ppdet.utils.download INFO: Downloading ResNet50_vd_ssld_v2_pretrained.pdparams from https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_vd_ssld_v2_pretrained.pdparams
  0%|          | 0/139208 [00:00<?, ?KB/s]  0%|          | 3/139208 [00:00<1:49:51, 21.12KB/s]  0%|          | 19/139208 [00:00<30:05, 77.09KB/s]   0%|          | 35/139208 [00:00<34:28, 67.28KB/s]  0%|          | 51/139208 [00:00<28:22, 81.72KB/s]  0%|          | 67/139208 [00:00<25:02, 92.59KB/s]  0%|          | 83/139208 [00:01<29:24, 78.83KB/s]  0%|          | 99/139208 [00:01<26:39, 86.96KB/s]  0%|          | 115/139208 [00:01<24:23, 95.06KB/s]  0%|          | 131/139208 [00:01<33:25, 69.34KB/s]  0%|          | 147/139208 [00:01<34:56, 66.33KB/s]  0%|          | 163/139208 [00:02<35:16, 65.69KB/s]  0%|          | 179/139208 [00:02<36:26, 63.58KB/s]  0%|          | 195/139208 [00:02<37:00, 62.61KB/s]  0%|          | 211/139208 [00:03<37:36, 61.60KB/s]  0%|          | 227/139208 [00:03<36:33, 63.37KB/s]  0%|          | 243/139208 [00:03<38:01, 60.91KB/s]  0%|          | 259/139208 [00:03<38:21, 60.39KB/s]  0%|          | 275/139208 [00:04<37:54, 61.09KB/s]  0%|          | 291/139208 [00:04<38:15, 60.51KB/s]  0%|          | 307/139208 [00:04<44:31, 51.99KB/s]  0%|          | 323/139208 [00:05<44:39, 51.82KB/s]  0%|          | 339/139208 [00:05<45:03, 51.36KB/s]  0%|          | 355/139208 [00:05<45:20, 51.04KB/s]  0%|          | 371/139208 [00:06<45:39, 50.68KB/s]  0%|          | 387/139208 [00:06<47:54, 48.29KB/s]  0%|          | 403/139208 [00:06<47:41, 48.51KB/s]  0%|          | 419/139208 [00:07<47:51, 48.33KB/s]  0%|          | 435/139208 [00:07<47:17, 48.91KB/s]  0%|          | 451/139208 [00:07<49:18, 46.90KB/s]  0%|          | 467/139208 [00:08<48:48, 47.38KB/s]  0%|          | 483/139208 [00:08<49:07, 47.06KB/s]  0%|          | 499/139208 [00:08<48:38, 47.52KB/s]  0%|          | 515/139208 [00:09<49:07, 47.06KB/s]  0%|          | 531/139208 [00:09<58:39, 39.40KB/s]  0%|          | 547/139208 [00:10<1:02:37, 36.91KB/s]  0%|          | 563/139208 [00:10<58:01, 39.82KB/s]    0%|          | 579/139208 [00:10<54:48, 42.16KB/s]  0%|          | 595/139208 [00:11<53:50, 42.91KB/s]  0%|          | 611/139208 [00:11<50:54, 45.37KB/s]  0%|          | 627/139208 [00:11<47:06, 49.03KB/s]  0%|          | 643/139208 [00:11<43:08, 53.52KB/s]  0%|          | 659/139208 [00:12<40:20, 57.23KB/s]  0%|          | 675/139208 [00:12<36:31, 63.21KB/s]  0%|          | 691/139208 [00:12<33:12, 69.51KB/s]  1%|          | 707/139208 [00:12<30:22, 75.99KB/s]  1%|          | 723/139208 [00:12<28:19, 81.47KB/s]  1%|          | 739/139208 [00:13<25:55, 89.00KB/s]  1%|          | 755/139208 [00:13<23:53, 96.58KB/s]  1%|          | 771/139208 [00:13<22:06, 104.39KB/s]  1%|          | 787/139208 [00:13<20:59, 109.91KB/s]  1%|          | 803/139208 [00:13<19:04, 120.92KB/s]  1%|          | 819/139208 [00:13<18:20, 125.77KB/s]  1%|          | 851/139208 [00:13<16:21, 141.00KB/s]  1%|          | 883/139208 [00:14<14:49, 155.45KB/s]  1%|          | 915/139208 [00:14<13:38, 168.90KB/s]  1%|          | 947/139208 [00:14<12:55, 178.26KB/s]  1%|          | 979/139208 [00:14<11:54, 193.41KB/s]  1%|          | 1011/139208 [00:14<11:03, 208.34KB/s]  1%|          | 1043/139208 [00:14<10:17, 223.83KB/s]  1%|          | 1075/139208 [00:14<09:49, 234.21KB/s]  1%|          | 1107/139208 [00:14<09:09, 251.45KB/s]  1%|          | 1139/139208 [00:15<08:34, 268.40KB/s]  1%|          | 1187/139208 [00:15<07:56, 289.55KB/s]  1%|          | 1235/139208 [00:15<07:25, 309.70KB/s]  1%|          | 1283/139208 [00:15<06:57, 330.17KB/s]  1%|          | 1331/139208 [00:15<06:32, 351.59KB/s]  1%|          | 1379/139208 [00:15<06:03, 379.52KB/s]  1%|          | 1427/139208 [00:15<05:44, 399.77KB/s]  1%|          | 1475/139208 [00:15<05:27, 420.85KB/s]  1%|          | 1539/139208 [00:16<05:08, 446.97KB/s]  1%|          | 1603/139208 [00:16<04:46, 479.95KB/s]  1%|          | 1667/139208 [00:16<04:31, 505.93KB/s]  1%|          | 1731/139208 [00:16<04:15, 539.09KB/s]  1%|▏         | 1811/139208 [00:16<03:58, 575.33KB/s]  1%|▏         | 1891/139208 [00:16<03:44, 611.60KB/s]  1%|▏         | 1971/139208 [00:16<03:31, 647.91KB/s]  1%|▏         | 2051/139208 [00:16<03:20, 684.54KB/s]  2%|▏         | 2147/139208 [00:16<03:08, 725.69KB/s]  2%|▏         | 2243/139208 [00:17<02:58, 767.84KB/s]  2%|▏         | 2339/139208 [00:17<02:47, 817.14KB/s]  2%|▏         | 2451/139208 [00:17<02:38, 863.15KB/s]  2%|▏         | 2563/139208 [00:17<02:29, 916.81KB/s]  2%|▏         | 2675/139208 [00:17<02:20, 970.78KB/s]  2%|▏         | 2803/139208 [00:17<02:12, 1027.82KB/s]  2%|▏         | 2931/139208 [00:17<02:05, 1086.33KB/s]  2%|▏         | 3075/139208 [00:17<01:58, 1148.88KB/s]  2%|▏         | 3219/139208 [00:17<01:52, 1212.34KB/s]  2%|▏         | 3379/139208 [00:18<01:45, 1287.71KB/s]  3%|▎         | 3539/139208 [00:18<01:39, 1363.23KB/s]  3%|▎         | 3715/139208 [00:18<01:33, 1441.63KB/s]  3%|▎         | 3891/139208 [00:18<01:28, 1528.30KB/s]  3%|▎         | 4083/139208 [00:18<01:23, 1611.54KB/s]  3%|▎         | 4291/139208 [00:18<01:19, 1707.59KB/s]  3%|▎         | 4499/139208 [00:18<01:14, 1802.33KB/s]  3%|▎         | 4723/139208 [00:18<01:10, 1902.92KB/s]  4%|▎         | 4963/139208 [00:18<01:06, 2016.16KB/s]  4%|▎         | 5210/139208 [00:18<01:02, 2147.57KB/s]  4%|▍         | 5459/139208 [00:19<00:59, 2239.28KB/s]  4%|▍         | 5731/139208 [00:19<00:56, 2362.91KB/s]  4%|▍         | 6019/139208 [00:19<00:53, 2498.51KB/s]  5%|▍         | 6323/139208 [00:19<00:50, 2644.94KB/s]  5%|▍         | 6643/139208 [00:19<00:47, 2785.55KB/s]  5%|▌         | 6979/139208 [00:19<00:44, 2940.18KB/s]  5%|▌         | 7331/139208 [00:19<00:42, 3106.31KB/s]  6%|▌         | 7699/139208 [00:19<00:40, 3269.79KB/s]  6%|▌         | 8099/139208 [00:19<00:37, 3457.40KB/s]  6%|▌         | 8515/139208 [00:19<00:35, 3645.85KB/s]  6%|▋         | 8961/139208 [00:20<00:33, 3886.87KB/s]  7%|▋         | 9411/139208 [00:20<00:32, 4050.27KB/s]  7%|▋         | 9895/139208 [00:20<00:30, 4284.78KB/s]  7%|▋         | 10403/139208 [00:20<00:28, 4502.45KB/s]  8%|▊         | 10947/139208 [00:20<00:26, 4758.70KB/s]  8%|▊         | 11523/139208 [00:20<00:25, 5022.01KB/s]  9%|▊         | 12131/139208 [00:20<00:23, 5315.59KB/s]  9%|▉         | 12771/139208 [00:20<00:22, 5601.63KB/s] 10%|▉         | 13443/139208 [00:20<00:21, 5911.38KB/s] 10%|█         | 14163/139208 [00:20<00:19, 6255.45KB/s] 11%|█         | 14915/139208 [00:21<00:18, 6615.23KB/s] 11%|█▏        | 15699/139208 [00:21<00:17, 6966.87KB/s] 12%|█▏        | 16531/139208 [00:21<00:16, 7342.50KB/s] 13%|█▎        | 17411/139208 [00:21<00:15, 7759.16KB/s] 13%|█▎        | 18339/139208 [00:21<00:14, 8188.59KB/s] 14%|█▍        | 19315/139208 [00:21<00:13, 8642.23KB/s] 15%|█▍        | 20355/139208 [00:21<00:12, 9149.53KB/s] 15%|█▌        | 21443/139208 [00:21<00:12, 9628.47KB/s] 16%|█▌        | 22595/139208 [00:21<00:11, 10162.67KB/s] 17%|█▋        | 23763/139208 [00:21<00:10, 10579.90KB/s] 18%|█▊        | 24867/139208 [00:22<00:10, 10709.12KB/s] 19%|█▊        | 26035/139208 [00:22<00:10, 10998.22KB/s] 20%|█▉        | 27155/139208 [00:22<00:10, 11053.62KB/s] 20%|██        | 28275/139208 [00:22<00:10, 11077.21KB/s] 21%|██        | 29463/139208 [00:22<00:09, 11316.50KB/s] 22%|██▏       | 30595/139208 [00:22<00:09, 11122.63KB/s] 23%|██▎       | 31763/139208 [00:22<00:09, 11255.34KB/s] 24%|██▎       | 32931/139208 [00:22<00:09, 11361.71KB/s] 24%|██▍       | 34068/139208 [00:22<00:09, 11247.75KB/s] 25%|██▌       | 35235/139208 [00:22<00:09, 11352.56KB/s] 26%|██▌       | 36371/139208 [00:23<00:09, 11316.15KB/s] 27%|██▋       | 37503/139208 [00:23<00:09, 11280.51KB/s] 28%|██▊       | 38691/139208 [00:23<00:08, 11444.71KB/s] 29%|██▊       | 39836/139208 [00:23<00:08, 11234.01KB/s] 29%|██▉       | 40979/139208 [00:23<00:08, 11279.46KB/s] 30%|███       | 42147/139208 [00:23<00:08, 11389.29KB/s] 31%|███       | 43287/139208 [00:23<00:08, 11267.47KB/s] 32%|███▏      | 44454/139208 [00:23<00:08, 11386.16KB/s] 33%|███▎      | 45594/139208 [00:23<00:08, 11316.09KB/s] 34%|███▎      | 46727/139208 [00:24<00:08, 11252.85KB/s] 34%|███▍      | 47923/139208 [00:24<00:07, 11442.46KB/s] 35%|███▌      | 49068/139208 [00:24<00:08, 11245.61KB/s] 36%|███▌      | 50203/139208 [00:24<00:07, 11276.19KB/s] 37%|███▋      | 51355/139208 [00:24<00:07, 11347.59KB/s] 38%|███▊      | 52491/139208 [00:24<00:07, 11294.24KB/s] 39%|███▊      | 53651/139208 [00:24<00:07, 11383.20KB/s] 39%|███▉      | 54790/139208 [00:24<00:07, 11358.47KB/s] 40%|████      | 55927/139208 [00:24<00:07, 11268.55KB/s] 41%|████      | 57107/139208 [00:24<00:07, 11420.80KB/s] 42%|████▏     | 58250/139208 [00:25<00:07, 11248.15KB/s] 43%|████▎     | 59395/139208 [00:25<00:07, 11286.62KB/s] 43%|████▎     | 60550/139208 [00:25<00:06, 11364.03KB/s] 44%|████▍     | 61687/139208 [00:25<00:06, 11231.09KB/s] 45%|████▌     | 62867/139208 [00:25<00:06, 11395.64KB/s] 46%|████▌     | 64008/139208 [00:25<00:06, 11353.96KB/s] 47%|████▋     | 65144/139208 [00:25<00:06, 11300.47KB/s] 48%|████▊     | 66307/139208 [00:25<00:06, 11394.19KB/s] 48%|████▊     | 67447/139208 [00:25<00:06, 11281.81KB/s] 49%|████▉     | 68595/139208 [00:25<00:06, 11278.70KB/s] 50%|█████     | 69763/139208 [00:26<00:06, 11393.38KB/s] 51%|█████     | 70903/139208 [00:26<00:06, 11252.17KB/s] 52%|█████▏    | 72083/139208 [00:26<00:05, 11398.36KB/s] 53%|█████▎    | 73224/139208 [00:26<00:05, 11326.64KB/s] 53%|█████▎    | 74358/139208 [00:26<00:05, 11304.84KB/s] 54%|█████▍    | 75520/139208 [00:26<00:05, 11398.12KB/s] 55%|█████▌    | 76661/139208 [00:26<00:05, 11283.80KB/s] 56%|█████▌    | 77811/139208 [00:26<00:05, 11319.56KB/s] 57%|█████▋    | 78979/139208 [00:26<00:05, 11404.87KB/s] 58%|█████▊    | 80120/139208 [00:26<00:05, 11255.09KB/s] 58%|█████▊    | 81283/139208 [00:27<00:05, 11327.70KB/s] 59%|█████▉    | 82419/139208 [00:27<00:05, 11334.21KB/s] 60%|██████    | 83555/139208 [00:27<00:04, 11319.86KB/s] 61%|██████    | 84691/139208 [00:27<00:04, 11318.90KB/s] 62%|██████▏   | 85824/139208 [00:27<00:04, 11300.62KB/s] 62%|██████▏   | 86963/139208 [00:27<00:04, 11322.03KB/s] 63%|██████▎   | 88115/139208 [00:27<00:04, 11371.62KB/s] 64%|██████▍   | 89253/139208 [00:27<00:04, 11215.85KB/s] 65%|██████▍   | 90435/139208 [00:27<00:04, 11384.83KB/s] 66%|██████▌   | 91574/139208 [00:27<00:04, 11311.24KB/s] 67%|██████▋   | 92717/139208 [00:28<00:04, 11346.36KB/s] 67%|██████▋   | 93852/139208 [00:28<00:04, 11318.81KB/s] 68%|██████▊   | 94985/139208 [00:28<00:03, 11240.43KB/s] 69%|██████▉   | 96147/139208 [00:28<00:03, 11350.78KB/s] 70%|██████▉   | 97311/139208 [00:28<00:03, 11436.74KB/s] 71%|███████   | 98455/139208 [00:28<00:03, 11224.40KB/s] 72%|███████▏  | 99635/139208 [00:28<00:03, 11367.91KB/s] 72%|███████▏  | 100773/139208 [00:28<00:03, 11292.70KB/s] 73%|███████▎  | 101923/139208 [00:28<00:03, 11344.64KB/s] 74%|███████▍  | 103059/139208 [00:28<00:03, 11312.41KB/s] 75%|███████▍  | 104191/139208 [00:29<00:03, 11308.76KB/s] 76%|███████▌  | 105323/139208 [00:29<00:02, 11309.73KB/s] 76%|███████▋  | 106483/139208 [00:29<00:02, 11338.49KB/s] 77%|███████▋  | 107617/139208 [00:29<00:02, 11279.53KB/s] 78%|███████▊  | 108787/139208 [00:29<00:02, 11395.72KB/s] 79%|███████▉  | 109927/139208 [00:29<00:02, 11306.68KB/s] 80%|███████▉  | 111060/139208 [00:29<00:02, 11313.07KB/s] 81%|████████  | 112192/139208 [00:29<00:02, 11282.43KB/s] 81%|████████▏ | 113326/139208 [00:29<00:02, 11299.47KB/s] 82%|████████▏ | 114467/139208 [00:29<00:02, 11294.03KB/s] 83%|████████▎ | 115651/139208 [00:30<00:02, 11442.99KB/s] 84%|████████▍ | 116796/139208 [00:30<00:01, 11262.52KB/s] 85%|████████▍ | 117960/139208 [00:30<00:01, 11373.68KB/s] 86%|████████▌ | 119098/139208 [00:30<00:01, 11289.83KB/s] 86%|████████▋ | 120243/139208 [00:30<00:01, 11292.61KB/s] 87%|████████▋ | 121379/139208 [00:30<00:01, 11273.20KB/s] 88%|████████▊ | 122531/139208 [00:30<00:01, 11267.59KB/s] 89%|████████▉ | 123683/139208 [00:30<00:01, 11335.55KB/s] 90%|████████▉ | 124851/139208 [00:30<00:01, 11420.34KB/s] 91%|█████████ | 125994/139208 [00:31<00:01, 11296.07KB/s] 91%|█████████▏| 127155/139208 [00:31<00:01, 11370.76KB/s] 92%|█████████▏| 128293/139208 [00:31<00:00, 11335.25KB/s] 93%|█████████▎| 129427/139208 [00:31<00:00, 11318.33KB/s] 94%|█████████▍| 130559/139208 [00:31<00:00, 11276.74KB/s] 95%|█████████▍| 131697/139208 [00:31<00:00, 11306.84KB/s] 95%|█████████▌| 132835/139208 [00:31<00:00, 11316.98KB/s] 96%|█████████▋| 134035/139208 [00:31<00:00, 11470.72KB/s] 97%|█████████▋| 135183/139208 [00:31<00:00, 11219.62KB/s] 98%|█████████▊| 136360/139208 [00:31<00:00, 11381.31KB/s] 99%|█████████▉| 137500/139208 [00:32<00:00, 11348.40KB/s]100%|█████████▉| 138636/139208 [00:32<00:00, 11327.23KB/s]100%|██████████| 139208/139208 [00:32<00:00, 4326.68KB/s] 
[05/03 04:50:22] ppdet.utils.checkpoint INFO: Finish loading model weights: /root/.cache/paddle/weights/ResNet50_vd_ssld_v2_pretrained.pdparams
[05/03 04:50:34] ppdet.engine INFO: Epoch: [0] [   0/2624] learning_rate: 0.000000 loss_class: 0.333002 loss_bbox: 1.700657 loss_giou: 1.622691 loss_class_aux: 2.065430 loss_bbox_aux: 10.299568 loss_giou_aux: 9.685238 loss_class_dn: 0.791966 loss_bbox_dn: 1.310511 loss_giou_dn: 1.349264 loss_class_aux_dn: 4.380806 loss_bbox_aux_dn: 6.552557 loss_giou_aux_dn: 6.746319 loss: 46.838013 eta: 26 days, 8:12:26 batch_cost: 12.0466 data_cost: 0.0005 ips: 0.3320 images/s
I0509 16:11:36.967296 93747 tcp_utils.cc:181] The server starts to listen on IP_ANY:60572
I0509 16:11:36.967464 93747 tcp_utils.cc:130] Successfully connected to 127.0.1.1:60572
W0509 16:11:40.977295 93747 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.4
W0509 16:11:40.979684 93747 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
[2023-05-09 16:11:43,458] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0, 1], check/clip group: [0]
loading annotations into memory...
Done (t=0.12s)
creating index...
index created!
[05/09 16:11:43] ppdet.data.source.oad INFO: Load [559 samples valid, 174 samples invalid] in file /DL_data_super_ssd/EFID2023/new_hallway/val/json/annotation.json.
[05/09 16:11:47] ppdet.utils.checkpoint INFO: Finish loading model weights: /root/.cache/paddle/weights/ResNet50_vd_ssld_v2_pretrained.pdparams
W0509 16:11:48.898432 93747 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
[05/09 16:11:49] ppdet.engine INFO: Epoch: [0] [ 0/70] learning_rate: 0.000000 loss_class: 0.226416 loss_bbox: 0.713112 loss_giou: 1.168282 loss_rad: 0.107143 loss_class_aux: 1.030613 loss_bbox_aux: 4.377598 loss_giou_aux: 7.069581 loss_rad_aux: 0.521571 loss_class_dn: 0.724333 loss_bbox_dn: 0.451724 loss_giou_dn: 0.911478 loss_rad_dn: 0.124089 loss_class_aux_dn: 2.695754 loss_bbox_aux_dn: 2.258618 loss_giou_aux_dn: 4.557391 loss_rad_aux_dn: 0.264180 loss: 27.201881 eta: 0:25:11 batch_cost: 2.1600 data_cost: 0.0003 ips: 1.8519 images/s


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Backward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool)
1   egr::RunBackward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&)
2   StackGradNode::operator()(paddle::small_vector<std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::stack_grad(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, paddle::experimental::Tensor const&, int, std::vector<paddle::experimental::Tensor*, std::allocator<paddle::experimental::Tensor*> >)
4   phi::KernelImpl<void (*)(phi::GPUContext const&, phi::DenseTensor const&, int, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >), &(void phi::StackGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >))>::VariadicCompute(phi::DeviceContext const&, phi::DenseTensor const&, int, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
5   void phi::StackGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, std::vector<phi::DenseTensor*, std::allocator<phi::DenseTensor*> >)
6   std::unique_ptr<phi::Allocation, std::function<void (phi::Allocation*)> >::~unique_ptr()
7   paddle::memory::allocation::Allocator::AllocationDeleter(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1683616314 (unix time) try "date -d @1683616314" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x16dd4) received by PID 93747 (TID 0x7f9f99d8a740) from PID 93652 ***]

I0509 16:12:06.103246 94880 tcp_utils.cc:181] The server starts to listen on IP_ANY:58255
I0509 16:12:06.103420 94880 tcp_utils.cc:130] Successfully connected to 127.0.1.1:58255
W0509 16:12:10.106976 94880 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.8, Runtime API Version: 11.4
W0509 16:12:10.109356 94880 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
[2023-05-09 16:12:12,579] [    INFO] topology.py:215 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0, 1], check/clip group: [0]
loading annotations into memory...
Done (t=1.63s)
creating index...
index created!
[05/09 16:12:18] ppdet.data.source.oad INFO: Load [10559 samples valid, 3545 samples invalid] in file /DL_data_super_ssd/EFID2023/new_hallway/train/json/annotation.json.
[05/09 16:12:21] ppdet.utils.checkpoint INFO: Finish loading model weights: /root/.cache/paddle/weights/ResNet50_vd_ssld_v2_pretrained.pdparams
W0509 16:12:23.528460 94880 reducer.cc:622] All parameters are involved in the backward pass. It is recommended to set find_unused_parameters to False to improve performance. However, if unused parameters appear in subsequent iterative training, then an error will occur. Please make it clear that in the subsequent training, there will be no parameters that are not used in the backward pass, and then set find_unused_parameters
[05/09 16:12:23] ppdet.engine INFO: Epoch: [0] [   0/1320] learning_rate: 0.000000 loss_class: 0.457412 loss_bbox: 1.444991 loss_giou: 2.346107 loss_rad: 0.180425 loss_class_aux: 2.902955 loss_bbox_aux: 8.696845 loss_giou_aux: 14.200708 loss_rad_aux: 0.917262 loss_class_dn: 0.921553 loss_bbox_dn: 1.056809 loss_giou_dn: 1.994975 loss_rad_dn: 0.139870 loss_class_aux_dn: 5.444083 loss_bbox_aux_dn: 5.284043 loss_giou_aux_dn: 9.974873 loss_rad_aux_dn: 0.490994 loss: 56.453907 eta: 7:43:53 batch_cost: 2.1086 data_cost: 0.0003 ips: 1.8970 images/s
[05/09 16:13:53] ppdet.engine INFO: Epoch: [0] [ 200/1320] learning_rate: 0.000010 loss_class: 0.297911 loss_bbox: 0.950319 loss_giou: 1.641074 loss_rad: 0.109339 loss_class_aux: 1.898633 loss_bbox_aux: 5.808609 loss_giou_aux: 10.087812 loss_rad_aux: 0.557504 loss_class_dn: 0.493887 loss_bbox_dn: 0.647489 loss_giou_dn: 1.419689 loss_rad_dn: 0.073333 loss_class_aux_dn: 2.642146 loss_bbox_aux_dn: 3.169850 loss_giou_aux_dn: 7.115860 loss_rad_aux_dn: 0.199933 loss: 38.808105 eta: 1:32:08 batch_cost: 0.4168 data_cost: 0.0003 ips: 9.5961 images/s
